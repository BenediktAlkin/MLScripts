{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80bfa781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/system/apps/userenv/alkin/default/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f06e30ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e56bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0571, -0.1370, -0.2169,  ...,  0.5390, -0.1141,  0.3640],\n",
      "        [ 0.5225, -0.8591,  0.5108,  ..., -0.3916,  0.4059, -0.5997],\n",
      "        [ 0.0561, -0.1040,  1.0566,  ...,  0.4401,  0.3889,  0.0049],\n",
      "        ...,\n",
      "        [-0.4902,  0.0272, -0.4503,  ...,  0.3274,  0.8314, -0.8121],\n",
      "        [ 0.7316, -0.3792, -0.3314,  ..., -0.7897,  0.5002, -0.0159],\n",
      "        [ 0.3468, -0.5296, -0.1580,  ..., -1.0617, -0.5325, -1.1135]],\n",
      "       device='cuda:6', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1024, 1024)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model, device_ids=[6, 7])\n",
    "print(model(torch.randn(32, 1024).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976bc24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7342,  0.3100,  0.0883,  ...,  0.5354, -0.8100,  1.1021],\n",
      "        [ 0.0995, -0.4837,  0.6038,  ..., -0.4872,  0.6613,  0.2326],\n",
      "        [-0.2703, -0.4442,  0.5208,  ..., -0.2856, -0.6850,  0.7463],\n",
      "        ...,\n",
      "        [ 0.7307, -0.2227,  0.0291,  ...,  1.0768, -1.3793,  0.7948],\n",
      "        [-0.6843,  0.2646,  0.3406,  ..., -0.2419,  0.7972,  0.8963],\n",
      "        [-0.0560, -0.4701,  0.3845,  ..., -0.3214,  0.0804,  0.2355]],\n",
      "       device='cuda:6', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1024, 1024)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model, device_ids=[6, 7])\n",
    "model.to(device)\n",
    "print(model(torch.randn(32, 1024).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "507b1170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6447,  0.0745,  0.0551,  ...,  0.5613, -0.4180,  1.0456],\n",
      "        [-0.2655, -0.0981, -0.9405,  ...,  0.6602, -0.0111,  0.2282],\n",
      "        [-0.7912, -0.9279, -0.9875,  ...,  0.2946,  0.1081,  0.7896],\n",
      "        ...,\n",
      "        [ 0.8561,  0.6211,  1.1048,  ..., -1.2597,  0.8631,  0.4595],\n",
      "        [ 0.7593,  0.6892, -0.1459,  ...,  0.5549, -0.1861,  0.6619],\n",
      "        [-0.0624,  1.0943, -0.5189,  ..., -0.1226,  0.1904,  0.3140]],\n",
      "       device='cuda:6', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1024, 1024)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model, device_ids=[6, 7])\n",
    "print(model(torch.randn(32, 1024).to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "499f7d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1013,  0.2817, -0.3589,  ..., -0.1329, -0.1013,  0.7614],\n",
      "        [-0.3360, -0.7355, -0.7325,  ..., -0.3156,  0.6271,  0.0536],\n",
      "        [ 0.0157,  0.7771,  0.0379,  ..., -0.5107,  0.7133, -0.4684],\n",
      "        ...,\n",
      "        [-0.0770,  0.8478,  0.7259,  ..., -0.3162, -1.0318, -0.5803],\n",
      "        [-0.0897, -0.7665,  0.2187,  ..., -0.1535, -0.5100,  0.5531],\n",
      "        [ 0.1691, -0.5203, -0.9593,  ...,  0.5960, -0.7067, -0.2455]],\n",
      "       device='cuda:6', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1024, 1024)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model, device_ids=[6, 7])\n",
    "print(model(torch.randn(32, 1024)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bfb329",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module must have its parameters and buffers on device cuda:6 (device_ids[0]) but found one of them on device: cpu",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-d760eb516ada>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1024\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1024\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataParallel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m7\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1024\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/system/apps/userenv/alkin/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/system/apps/userenv/alkin/default/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mchain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodule\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuffers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msrc_device_obj\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m                     raise RuntimeError(\"module must have its parameters and buffers \"\n\u001B[0m\u001B[1;32m    155\u001B[0m                                        \u001B[0;34m\"on device {} (device_ids[0]) but found one of \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m                                        \"them on device: {}\".format(self.src_device_obj, t.device))\n",
      "\u001B[0;31mRuntimeError\u001B[0m: module must have its parameters and buffers on device cuda:6 (device_ids[0]) but found one of them on device: cpu"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1024, 1024)\n",
    "model = nn.DataParallel(model, device_ids=[6, 7])\n",
    "print(model(torch.randn(32, 1024)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}